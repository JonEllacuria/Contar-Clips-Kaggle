{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 9.535226618997747\n",
      "R2 score: 0.9802249285163469\n",
      "RMSE: 3.0879162260329776\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Leer el archivo CSV con las respuestas correctas\n",
    "csv_file = \"train/train.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Crear listas para almacenar las características y las etiquetas\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Procesar cada imagen y extraer las características\n",
    "images_folder = 'train/train'\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        # Leer la imagen\n",
    "        img_path = os.path.join(images_folder, filename)\n",
    "        img = cv.imread(img_path)\n",
    "        # Extraer las características de la imagen (por ejemplo, el número de contornos)\n",
    "        hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "        histogram = cv.calcHist([hsv_img], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "        most_common_color_index = np.unravel_index(np.argmax(histogram), histogram.shape)\n",
    "        lower_red = np.array([0, 25, 25])\n",
    "        upper_red = np.array([255, 255, 255])\n",
    "        mask = cv.inRange(hsv_img, lower_red, upper_red)\n",
    "        red_pixels = np.where(mask == 255)\n",
    "        most_common_color_hsv = (most_common_color_index[0], most_common_color_index[1], 255)\n",
    "        most_common_color_bgr = cv.cvtColor(np.uint8([[most_common_color_hsv]]), cv.COLOR_HSV2BGR)[0][0]\n",
    "        img[red_pixels] = most_common_color_bgr\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv.threshold(blurred, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "        contours, _ = cv.findContours(thresh, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "        num_contours = len(contours)\n",
    "    \n",
    "        # Obtener el número real de clips del archivo CSV correspondiente\n",
    "        image_id = int(filename.split('-')[1].split('.')[0])\n",
    "        real_clips = df.loc[df['id'] == image_id, 'clip_count'].values[0]\n",
    "\n",
    "        # Agregar las características y la etiqueta a las listas\n",
    "        features.append(num_contours)\n",
    "        labels.append(real_clips)\n",
    "\n",
    "# Convertir las listas en arrays numpy\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo (ejemplo utilizando Random Forest)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = model.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2 score: {r2}\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 9.261517683637079\n",
      "R2 score: 0.9807281514045729\n",
      "RMSE: 3.043274171617976\n"
     ]
    }
   ],
   "source": [
    "#Entreno con toda la data\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Leer el archivo CSV con las respuestas correctas\n",
    "csv_file = \"train/train.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Crear listas para almacenar las características y las etiquetas\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Procesar cada imagen y extraer las características\n",
    "images_folder = 'train/train'\n",
    "for filename in os.listdir(images_folder):\n",
    "    if filename.endswith('.png'):\n",
    "        # Leer la imagen\n",
    "        img_path = os.path.join(images_folder, filename)\n",
    "        img = cv.imread(img_path)\n",
    "        # Extraer las características de la imagen (por ejemplo, el número de contornos)\n",
    "        hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "        histogram = cv.calcHist([hsv_img], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "        most_common_color_index = np.unravel_index(np.argmax(histogram), histogram.shape)\n",
    "        lower_red = np.array([0, 25, 25])\n",
    "        upper_red = np.array([255, 255, 255])\n",
    "        mask = cv.inRange(hsv_img, lower_red, upper_red)\n",
    "        red_pixels = np.where(mask == 255)\n",
    "        most_common_color_hsv = (most_common_color_index[0], most_common_color_index[1], 255)\n",
    "        most_common_color_bgr = cv.cvtColor(np.uint8([[most_common_color_hsv]]), cv.COLOR_HSV2BGR)[0][0]\n",
    "        img[red_pixels] = most_common_color_bgr\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv.threshold(blurred, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "        contours, _ = cv.findContours(thresh, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "        num_contours = len(contours)\n",
    "    \n",
    "        # Obtener el número real de clips del archivo CSV correspondiente\n",
    "        image_id = int(filename.split('-')[1].split('.')[0])\n",
    "        real_clips = df.loc[df['id'] == image_id, 'clip_count'].values[0]\n",
    "\n",
    "        # Agregar las características y la etiqueta a las listas\n",
    "        features.append(num_contours)\n",
    "        labels.append(real_clips)\n",
    "\n",
    "# Convertir las listas en arrays numpy\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo (ejemplo utilizando Random Forest)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(features.reshape(-1, 1), labels)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "y_pred = model.predict(features.reshape(-1, 1))\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "mse = mean_squared_error(labels, y_pred)\n",
    "r2 = r2_score(labels, y_pred)\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2 score: {r2}\")\n",
    "print(f\"RMSE: {np.sqrt(mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(patience=5)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcheckpoint = ModelCheckpoint(\"callback_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, input_shape=IMAGE_SIZE\n",
    "layers = [\n",
    "    keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='linear')  # Cambio de la función de activación a lineal\n",
    "]\n",
    "\n",
    "model = keras.Sequential(layers)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',  # Cambio de la función de pérdida a MSE\n",
    "              metrics=['mean_squared_error'])  # Opcional: Puedes utilizar métricas adecuadas para la regresión, como MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "         y_train,\n",
    "         epochs = 10,\n",
    "         batch_size = 100,\n",
    "         callbacks = [earlystop, mcheckpoint],\n",
    "         validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "features2 = []\n",
    "\n",
    "images_folder2 = 'test/test'\n",
    "for filename in os.listdir(images_folder2):\n",
    "    if filename.endswith('.png'):\n",
    "        # Leer la imagen\n",
    "        img_path = os.path.join(images_folder2, filename)\n",
    "        img = cv.imread(img_path)\n",
    "\n",
    "        # Extraer las características de la imagen (por ejemplo, el número de contornos)\n",
    "        hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "        histogram = cv.calcHist([hsv_img], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "        most_common_color_index = np.unravel_index(np.argmax(histogram), histogram.shape)\n",
    "        lower_red = np.array([0, 25, 25])\n",
    "        upper_red = np.array([255, 255, 255])\n",
    "        mask = cv.inRange(hsv_img, lower_red, upper_red)\n",
    "        red_pixels = np.where(mask == 255)\n",
    "        most_common_color_hsv = (most_common_color_index[0], most_common_color_index[1], 255)\n",
    "        most_common_color_bgr = cv.cvtColor(np.uint8([[most_common_color_hsv]]), cv.COLOR_HSV2BGR)[0][0]\n",
    "        img[red_pixels] = most_common_color_bgr\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv.threshold(blurred, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "        contours, _ = cv.findContours(thresh, cv.RETR_LIST, cv.CHAIN_APPROX_NONE)\n",
    "        num_contours = len(contours)\n",
    "\n",
    "        # Obtener el número real de clips del archivo CSV correspondiente\n",
    "        image_id = int(filename.split('-')[1].split('.')[0])\n",
    "        \n",
    "\n",
    "        # Agregar las características y la etiqueta a las listas\n",
    "        features2.append(num_contours)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = np.array(features2)\n",
    "y_pred2 = model.predict(features2.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_solucion=pd.read_csv(\"test/test.csv\")\n",
    "ids_solucion[\"clip_count\"]=y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_solucion.to_csv(\"solucion2.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
